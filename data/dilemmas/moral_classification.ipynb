{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moral Foundations Classification of SCU Dilemma Dataset\n",
    "\n",
    "This notebook performs moral foundation classification on a dataset of dilemmas using the [MoralFoundationsClassifier](https://huggingface.co/MMADS/MoralFoundationsClassifier) classifier. \n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. Cloning the classifier model from Hugging Face.\n",
    "2. Loading the model, tokenizer, and label mappings.\n",
    "3. Reading the dilemma dataset from a CSV file.\n",
    "4. Running the classifier on each dilemma, handling long texts by chunking.\n",
    "5. Averaging the model's predictions across text chunks for each moral foundation.\n",
    "6. Saving the results, including the most probable moral foundation per dilemma, to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21047,
     "status": "ok",
     "timestamp": 1746598314134,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "WhjOV-8NXhZX",
    "outputId": "accd37b7-58a7-42cb-f457-d65f3355c318"
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/MMADS/MoralFoundationsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84130,
     "status": "ok",
     "timestamp": 1746600316633,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "9w7ZZpujb_UY",
    "outputId": "0b3783f7-166e-4dde-8463-3a532848e5dd"
   },
   "outputs": [],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1746601989068,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "19u4pJZWaOIR"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "loading the model and tokenizer and labels\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import json\n",
    "\n",
    "model_path = \"MoralFoundationsClassifier\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "with open(f\"{model_path}/label_names.json\") as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1746601992836,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "JBSryqUncOFA"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the dilemma dataset\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "input_path = \"crafting_tech_8_business_ethics.csv\"\n",
    "df = pd.read_csv(input_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9566,
     "status": "ok",
     "timestamp": 1746602127708,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "-DA7J9cdhVtC",
    "outputId": "3ae03691-b51e-4bb6-8a52-fcb43f31e7bd"
   },
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "# 1. Build your pipeline once\n",
    "pipeline = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    framework=\"pt\",\n",
    "    # return_all_scores=True,\n",
    "    top_k=None,\n",
    "    function_to_apply=\"sigmoid\"\n",
    ")\n",
    "\n",
    "# 2. Define a chunking function\n",
    "def chunk_text(text, tokenizer, chunk_size=512, stride=256):\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False\n",
    "    )[\"input_ids\"][0]\n",
    "    chunks = []\n",
    "    for start in range(0, len(tokens), chunk_size - stride):\n",
    "        end = start + chunk_size\n",
    "        chunk_ids = tokens[start:end]\n",
    "        chunks.append(tokenizer.decode(chunk_ids, skip_special_tokens=True))\n",
    "        if end >= len(tokens):\n",
    "            break\n",
    "    return chunks\n",
    "\n",
    "results = []\n",
    "for _, row in df.iterrows():\n",
    "    text = row[\"Content\"]\n",
    "    # 3. Split the text into chunks\n",
    "    chunks = chunk_text(text, tokenizer, chunk_size=512, stride=256)\n",
    "\n",
    "    # 4. Get a dict of label→score for each chunk\n",
    "    chunk_scores = [\n",
    "        {\n",
    "            item[\"label\"]: item[\"score\"]\n",
    "            for item in pipeline(\n",
    "                chunk,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )[0]   # [0] unwraps the list-of-dicts for this single input\n",
    "        }\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "\n",
    "    # 5. Average each label’s score across all chunks\n",
    "    idx_to_label = {f\"LABEL_{i}\": name for i, name in enumerate(label_names)}\n",
    "    # 1) Remap each chunk's dict from LABEL_i → score to label_name → score\n",
    "    mapped_chunk_scores = [\n",
    "        {idx_to_label[k]: v for k, v in chunk.items()}\n",
    "        for chunk in chunk_scores\n",
    "    ]\n",
    "\n",
    "    # 2) Compute the average score per moral category\n",
    "    avg_scores = {\n",
    "        label: sum(d[label] for d in mapped_chunk_scores) / len(mapped_chunk_scores)\n",
    "        for label in label_names\n",
    "    }\n",
    "\n",
    "    # 6. Merge with original row and collect\n",
    "    results.append({**row.to_dict(), **avg_scores})\n",
    "\n",
    "# 7. Save back to Excel as before\n",
    "out_df = pd.DataFrame(results)\n",
    "output_path = \"moral_classification_results.xlsx\"\n",
    "out_df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1746602313815,
     "user": {
      "displayName": "mozhdeh hajiani",
      "userId": "17349947778060869975"
     },
     "user_tz": -210
    },
    "id": "fb1utzdbldXR",
    "outputId": "78a5cffe-a4fe-4c53-de2f-2dccca522b3f"
   },
   "outputs": [],
   "source": [
    "# moral‑foundation columns:\n",
    "moral_labels = [\n",
    "    \"care_virtue\",\"care_vice\",\n",
    "    \"fairness_virtue\",\"fairness_vice\",\n",
    "    \"loyalty_virtue\",\"loyalty_vice\",\n",
    "    \"authority_virtue\",\"authority_vice\",\n",
    "    \"sanctity_virtue\",\"sanctity_vice\"\n",
    "]\n",
    "\n",
    "# 1. Compute the max probability score per row\n",
    "out_df[\"max_score\"] = out_df[moral_labels].max(axis=1)\n",
    "\n",
    "# 2. Identify which label gave that max score\n",
    "out_df[\"max_label\"] = out_df[moral_labels].idxmax(axis=1)\n",
    "\n",
    "# 3. new column appear at the end\n",
    "cols = out_df.columns.tolist()\n",
    "new_order = [c for c in cols if c not in (\"max_score\",\"max_label\")] + [\"max_score\",\"max_label\"]\n",
    "out_df = out_df[new_order]\n",
    "\n",
    "output_path = \"moral_classification_scored.xlsx\"\n",
    "# 4. Save back to Excel\n",
    "out_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Saved enriched results to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO6uRVD2mWk6dqXjWMB3XGk",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
