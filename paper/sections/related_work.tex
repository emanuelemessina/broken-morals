\section{Related Work}

%Don’t review everything under the sun. Focus only on Problem Y.
%• Keep it to one page. If it drags on, you’re overcompensating.
%• End with this line: "To sum up, previous work has failed to address Y." Boom.
%• Can’t pinpoint a clear Y? Rewrite your Abstract/Intro/Related Work

In the current business landscape, complex corporate structures and pervasive technology have amplified concerns regarding organizational moral misalignment \cite{martinez}. This misalignment (a divergence between an organization's professed ethical values and the actual moral reasoning guiding its decisions) can foster ethical conflicts within the workplace. As Hyatt and Gruenglas \cite{hyatt} highlight, such conflicts "have profound effects on morals, code of conduct, and norms among stakeholders, which can ultimately undermine an organizational mission and its articulated values." High-profile cases like Volkswagen's emissions fraud \cite{ameen_2020} underscore how systemic failures can arise from unaddressed ethical weaknesses. These moral blind spots often originate not from deliberate misconduct but from structural and cognitive limitations within organizations \cite{sezer_etal_2015}.

To address such ethical challenges, scholarly work in business ethics has long investigated how ethical culture, principled leadership, and stakeholder governance influence organizational behavior \cite{donaldson_preston_1995}. However, despite these efforts, a growing body of research highlights key limitations. Past efforts to address these issues have often fallen short, partly because traditional top-down ethics reviews or approaches with limited stakeholder involvement frequently fail to capture the diversity of internal perspectives before critical decisions are made \cite{mitchell2020stakeholder, kujala}.

This gap becomes particularly evident with the increasing centrality of algorithmic systems in organizational decision-making. Despite this, the modeling of internal moral deliberation remains notably underexplored in computer science. Current computer science ethics research predominantly focuses on issues like fairness in machine learning \cite{mehrabi2022survey}, bias mitigation\cite{bianchi2023easily}, interpretability \cite{doshi-velez2017towards}, and responsible AI design principles \cite{ leslieunderstanding, sandersonimplementing,sekrstai,sadek2025challenges}. While vital, these inquiries primarily address AI system outputs, not the organizational dialogues that inform their development \cite{madaio_etal_2020}. A notable gap remains in the application of computational methods to simulate internal ethical deliberations, especially those capturing conflicting viewpoints across diverse organizational roles \cite{herdel2024exploregen}. This stands in contrast to AI alignment research, which primarily aims to align agent objectives with broad human values \cite{gabrielartificial}. Consequently, a key challenge is to develop computational models capable of representing and analyzing the complexity of moral pluralism within organizations \cite{sekrstai}.

To bridge  this interdisciplinary gap, research is drawing from "In Silico Sociology" and plural-agent systems. In Silico Sociology uses computational agents to simulate complex social phenomena, offering a powerful lens to examine interactions across varied social roles and cultural norms, often leveraging Large Language Models (LLMs) \cite{kozlowski_etal_2024, gilbert_2022}. Agent-based models are increasingly used for simulating policy debates and moral scenarios \cite{ shults_etal_2020}. A notable advancement is the development of generative agent simulations involving over 1,000 agents modeled on real individuals via qualitative interviews \cite{park_etal_2024_1000}. These simulations use LLMs to enable agents with specific personas (e.g., executive, engineer) to engage in structured moral deliberations. Furthermore, systems like "Plurals" are being developed to guide multi-agent deliberations, with LLMs potentially acting as moderators or structuring interactions \cite{ashkinaze_etal_2025}. Such techniques allow researchers to identify consensus and disagreement, offering new insights into organizational ethical conflicts and providing scalable methods to evaluate ethical interventions \cite{rao_etal_2025_riskrags}.

By integrating  insights from organizational behavior, responsible AI, and computational social science, we propose a new approach to understanding how ethical decisions are formed within complex institutions. While traditional business ethics research has long focused on leadership, values,orporate responsibility, and governance, and computer science has prioritized algorithmic fairness,bias mitigation, and transparency,these domains have largely evolved in parallel. Few efforts have bridged these fields to examine how diverse internal perspectives shape ethical decision-making in real-world decision-making. To sum up, our work addresses this interdisciplinary gap by introducing a system of multi-agent deliberation to simulate internal moral reasoning across organizational roles.
