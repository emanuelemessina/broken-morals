\section{Related Work}

%Don’t review everything under the sun. Focus only on Problem Y.
%• Keep it to one page. If it drags on, you’re overcompensating.
%• End with this line: "To sum up, previous work has failed to address Y." Boom.
%• Can’t pinpoint a clear Y? Rewrite your Abstract/Intro/Related Work

In the current business landscape, complex corporate structures and pervasive technology have amplified concerns regarding organizational moral misalignment \cite{martinez}. This misalignment (a divergence between an organization's professed ethical values and the actual moral reasoning guiding its decisions) can foster ethical conflicts within the workplace. As Hyatt and Gruenglas \cite{hyatt} highlight, such conflicts "have profound effects on morals, code of conduct, and norms among stakeholders, which can ultimately undermine an organizational mission and its articulated values." High-profile cases like Volkswagen's emissions fraud \cite{ameen_2020} underscore how systemic failures can arise from unaddressed ethical weaknesses. These moral blind spots often originate not from deliberate misconduct but from structural and cognitive limitations within organizations \cite{sezer_etal_2015}.

To address such ethical challenges, scholarly work in business ethics has long investigated how ethical culture, principled leadership, and stakeholder governance influence organizational behavior \cite{donaldson_preston_1995}. However, despite these efforts, a growing body of research highlights key limitations. Past efforts to address these issues have often fallen short, partly because traditional top-down ethics reviews or approaches with limited stakeholder involvement frequently fail to capture the diversity of internal perspectives before critical decisions are made \cite{mitchell2020stakeholder, kujala}.

This gap becomes particularly evident with the increasing centrality of algorithmic systems in organizational decision-making. Despite this, the modeling of internal moral deliberation remains notably underexplored in computer science. Current computer science ethics research predominantly focuses on issues like fairness in machine learning \cite{mehrabi2022survey}, bias mitigation \cite{bianchi2023easily}, interpretability \cite{doshi-velez2017towards}, and responsible AI design principles \cite{leslieunderstanding, sandersonimplementing,sekrstai,sadek2025challenges}. While vital, these inquiries primarily address AI systems outputs, and often overlook the internal organizational challenges and ethical reflections that influence their development. Recent work has begun to surface these complexities, highlighting the barriers faced by ethics advocates within organizations, such as the struggle to prioritize ethics in product-centric environments and the challenges posed by frequent team reorganizations \cite{Ali2023walking}. A notable gap remains in the application of computational methods to simulate internal ethical deliberations, especially those capturing conflicting viewpoints across diverse organizational roles. This stands in contrast to AI alignment research, which primarily aims to align agent objectives with broad human values \cite{gabrielartificial}. Consequently, a key challenge is to develop computational models capable of representing the complexity of moral pluralism within organizations \cite{sekrstai}.

To bridge this interdisciplinary gap, research is drawing from agent-based models \cite{gilbert_2022}. In Silico Sociology \cite{kozlowski_etal_2024} uses agents powered by Large Language Models (LLMs) to simulate complex social phenomena, offering a powerful lens to examine interactions across varied social roles and cultural norms. Agent-based models are increasingly used for simulating policy debates and moral scenarios. A notable advancement is the development of generative agent simulations involving over 1000 agents modeled on real individuals via qualitative interviews \cite{park_etal_2024_1000}. These simulations use LLMs to enable agents with specific personas to engage in structured social deliberations. Furthermore, systems like Plurals \cite{ashkinaze_etal_2025} are being developed to guide multi-agent deliberations, with LLMs potentially acting as moderators or structuring interactions. Such techniques could allow researchers to identify areas of consensus and disagreement in organizational ethical conflicts, offering new insights and providing scalable methods to evaluate ethical interventions. However, none of these techniques have been applied to the contex of organizational moral misalignment.

While traditional business ethics research has long focused on leadership, values, corporate responsibility, and governance, and computer science has prioritized algorithmic fairness, bias mitigation, and transparency, these domains have largely evolved in parallel. Few efforts have bridged these fields to examine how diverse internal perspectives shape ethical decisions in real-world decision-making.
To sum up, previous work has failed to efficiently address the inclusion of diverse perspectives in the context of company ethical decision-making.

By integrating insights from organizational behavior, responsible AI, and computational social science, we propose a new approach to support the formation of ethical decisions within complex institutions. Our work addresses this objective by introducing a multi-agent deliberation system to simulate internal moral reasoning across diverse organizational roles.
